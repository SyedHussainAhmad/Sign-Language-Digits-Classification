{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79dede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7967e4",
   "metadata": {},
   "source": [
    "# Create Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b753e2a3-8b34-422c-a330-36bf41c5689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignLanguageDigits(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, shape, train=True, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(shape),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Split data into train/test (80/20)\n",
    "        for label in range(10):\n",
    "            digit_dir = os.path.join(root_dir, str(label))\n",
    "            images = [img for img in os.listdir(digit_dir) if img.endswith('.JPG')]\n",
    "            split_idx = int(0.8 * len(images))   \n",
    "            \n",
    "            if train:\n",
    "                images = images[:split_idx]\n",
    "            else:\n",
    "                images = images[split_idx:]\n",
    "                \n",
    "            for img_name in images:\n",
    "                self.image_paths.append(os.path.join(digit_dir, img_name))\n",
    "                self.labels.append(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure 3 channels\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Replace the MNIST dataset loading with:\n",
    "train_dataset = SignLanguageDigits(\n",
    "    root_dir='Sign-Language-Digits-Dataset/Dataset',\n",
    "    shape=(64, 64),  # Resize to 64x64\n",
    "    train=True\n",
    ")\n",
    "\n",
    "test_dataset = SignLanguageDigits(\n",
    "    root_dir='Sign-Language-Digits-Dataset/Dataset',\n",
    "    shape=(64, 64),\n",
    "    train=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e9f331",
   "metadata": {},
   "source": [
    "# Create and Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27689074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n"
     ]
    }
   ],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, num_classes): # constructor of NN with its attributes\n",
    "\n",
    "        super(NN, self).__init__() # calling constructor of base class  \n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "        # callable objects\n",
    "\n",
    "    def forward(self, x):  # we must provid imp of forward () of nn.Module in our subclass\n",
    "\n",
    "        x = F.relu(self.fc1(x)) # //can do F.softmax(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  #         x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = 12288 # 3x64x64 = 12,288 size of sign images (RGB)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "# create NN object and move it to device\n",
    "\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        data = data.reshape(data.shape[0], -1) #[64,3x64x64]=[64, 12288]\n",
    "\n",
    "        # forward propagation\n",
    "        scores = model(data) #automatically call the forward method,\n",
    "\n",
    "        loss = criterion(scores, targets) # compute cost/loss on 64 example\n",
    "\n",
    "        # zero previous gradients\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        # back-propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a90c4",
   "metadata": {},
   "source": [
    "# Create and Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54e3274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)   # 3 input image channels (RGB), 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # 6 input channels (RGB), 16 output channels, 5x5 square convolution kernel\n",
    "        # Calculate the correct size for the first linear layer\n",
    "        # For 64x64 input:\n",
    "        # After conv1 (5x5 kernel): 64-5+1 = 60x60\n",
    "        # After pool1 (2x2): 30x30\n",
    "        # After conv2 (5x5 kernel): 30-5+1 = 26x26\n",
    "        # After pool2 (2x2): 13x13\n",
    "        # So final size is 16*13*13 = 2704\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "\n",
    "\n",
    "# Training setup for the CNN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create CNN model\n",
    "cnn_model = Net().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to device\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Forward pass - no need to reshape for CNN!\n",
    "        scores = cnn_model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0250ff5",
   "metadata": {},
   "source": [
    "# Test NN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55095af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Test accuracy: \n",
      "Got 324 / 418 with accuracy 77.51\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy function for NN\n",
    "def check_NN_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # 1. our model deactivates all the layers (eg.batch normalization/dropout)\n",
    "    with torch.no_grad(): #2.  not make computational graph\n",
    "        for x, y in loader:\n",
    "            #print (x.shape)\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "           \n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            \n",
    "            scores = model(x)\n",
    "                      \n",
    "            _, predictions = scores.max(1) #. it return max value and its index, 1 mean see column-wise \n",
    "            \n",
    "            num_correct += (predictions == y).sum() # compare prediction with y, if equal sum them to count the number of same values\n",
    "            num_samples += predictions.size(0)  #64, get no of samples\n",
    "            \n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy\" f\" {float(num_correct) / float(num_samples) * 100:.2f}\")\n",
    "\n",
    "        \n",
    "print (\"NN Test accuracy: \")\n",
    "check_NN_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227b809",
   "metadata": {},
   "source": [
    "# Test CNN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e6a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Test accuracy:\n",
      "Got 366 / 418 with accuracy 87.56%\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy function for CNN\n",
    "def check_CNN_accuracy(loader, cnn_model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    cnn_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            # No reshaping needed for CNN\n",
    "            scores = cnn_model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            \n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}%\")\n",
    "\n",
    "# Test the CNN\n",
    "print(\"CNN Test accuracy:\")\n",
    "check_CNN_accuracy(test_loader, cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fecd47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet-specific transforms\n",
    "resnet_transform = transforms.Compose([\n",
    "    transforms.Resize(256),          # First resize to 256x256\n",
    "    transforms.CenterCrop(224),      # Then crop to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets with ResNet transforms\n",
    "resnet_train_dataset = SignLanguageDigits(\n",
    "    root_dir='Sign-Language-Digits-Dataset/Dataset',\n",
    "    shape=(64, 64),\n",
    "    train=True,\n",
    "    transform=resnet_transform \n",
    ")\n",
    "\n",
    "resnet_test_dataset = SignLanguageDigits(\n",
    "    root_dir='Sign-Language-Digits-Dataset/Dataset',\n",
    "    shape=(64, 64),\n",
    "    train=False,\n",
    "    transform=resnet_transform\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "resnet_train_loader = DataLoader(resnet_train_dataset, batch_size=64, shuffle=True)\n",
    "resnet_test_loader = DataLoader(resnet_test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7264c8a",
   "metadata": {},
   "source": [
    "# ResNet with all freezed layers except last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8329b18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\jnotebooks\\assignment3_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dell\\jnotebooks\\assignment3_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "ResNet(all freezed layers) Test Accuracy:\n",
      "Got 371 / 418 with accuracy 88.76%\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet and modify it\n",
    "resnet1_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in resnet1_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify final layer for 10 classes\n",
    "num_features = resnet1_model.fc.in_features\n",
    "resnet1_model.fc = nn.Linear(num_features, 10)  # 10 output classes\n",
    "\n",
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet1_model = resnet1_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet1_model.fc.parameters(), lr=0.001)  # Only train final layer\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    resnet1_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in resnet_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet1_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}')\n",
    "\n",
    "# Evaluation\n",
    "def check_accuracy(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%\")\n",
    "\n",
    "print(\"ResNet(all freezed layers) Test Accuracy:\")\n",
    "check_accuracy(resnet_test_loader, resnet1_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1ba10",
   "metadata": {},
   "source": [
    "# ResNet with half freezed layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b865f9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "ResNet 2 Test Accuracy:\n",
      "Got 413 / 418 with accuracy 98.80%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resnet2_model = models.resnet18(pretrained=True)\n",
    "# Get a list Of all the layers in the model\n",
    "layers = list(resnet2_model .children())\n",
    "# Determine the halfway point\n",
    "halfway = len(layers) // 2\n",
    "# Freeze the first half of the layers\n",
    "for layer in layers[:halfway]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Leave the second half of the layers unfrozen for fine-tuning\n",
    "for layer in layers[halfway:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# replace the last fully connected layer (fc) with a new one for 10-class classification\n",
    "num_features = resnet2_model.fc.in_features\n",
    "resnet2_model.fc = nn.Linear(num_features, 10) # 10 output classes\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet2_model = resnet2_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet2_model.parameters(), lr=1e-4) \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    resnet2_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in resnet_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet2_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}')\n",
    "\n",
    "# Evaluation\n",
    "def check_accuracy(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%\")\n",
    "\n",
    "print(\"ResNet 2 Test Accuracy:\")\n",
    "check_accuracy(resnet_test_loader, resnet2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293a2fa",
   "metadata": {},
   "source": [
    "# ResNet with only last Freezed layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6335b0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\jnotebooks\\assignment3_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dell\\jnotebooks\\assignment3_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "ResNet 3 Test Accuracy:\n",
      "Got 413 / 418 with accuracy 98.80%\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet-18\n",
    "resnet3_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Unfreeze ALL layers for full fine-tuning\n",
    "for param in resnet3_model.parameters():\n",
    "    param.requires_grad = True  # All weights will be updated\n",
    "\n",
    "# Replace final layer for 10-class classification\n",
    "num_features = resnet3_model.fc.in_features\n",
    "resnet3_model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet3_model = resnet3_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet3_model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    resnet3_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in resnet_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet3_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}')\n",
    "\n",
    "# Evaluation\n",
    "def check_accuracy(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%\")\n",
    "\n",
    "print(\"ResNet 3 Test Accuracy:\")\n",
    "check_accuracy(resnet_test_loader, resnet3_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
